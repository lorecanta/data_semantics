{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_model_and_files, get_model_details, reconstruct_word, merge_results, preprocess_text, preprocess_stopwords, preprocess_lemmatization, traduci_output, process_text_with_models, process_emotions_and_translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento modello 1: osiria/bert-italian-uncased-ner\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento modello 2: IVN-RIN/MedPsyNIT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento modello 3: SamLowe/roberta-base-go_emotions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento modello 4: Helsinki-NLP/opus-mt-it-en\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lore9\\Documents\\GitHub\\data_semantics\\.venv\\Lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "# 1. Recupera i dettagli dei modelli\n",
    "model_details = get_model_details()\n",
    "\n",
    "# 2. Assegna manualmente le tuple a  separate\n",
    "(model_1_id, model_1_type, model_1_files), (model_2_id, model_2_type, model_2_files), (model_3_id, model_3_type, model_3_files), (model_4_id, model_4_type, model_4_files) = model_details\n",
    "\n",
    "# 3. Usa i dettagli per caricare i modelli\n",
    "print(f\"Caricamento modello 1: {model_1_id}\")\n",
    "model_1_pipeline = load_model_and_files(model_1_id, model_type=model_1_type)\n",
    "\n",
    "print(f\"Caricamento modello 2: {model_2_id}\")\n",
    "model_2_pipeline = load_model_and_files(model_2_id, model_type=model_2_type)\n",
    "\n",
    "print(f\"Caricamento modello 3: {model_3_id}\")\n",
    "model_3_pipeline = load_model_and_files(model_3_id, model_type=model_3_type)\n",
    "\n",
    "print(f\"Caricamento modello 4: {model_4_id}\")\n",
    "model_4_pipeline = load_model_and_files(model_4_id, model_type=model_4_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Ciao Giulia, devo prendere un volo transoceanico per la prima volta nella mia vita tra due settimane e vivo nel terrore che possa cadere. Boeing non fa aerei molto sicuri a mio avviso. Devo andare da londra a parigi per lavoro. Per l'ansia prenderò un lexotan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Connetti al database MongoDB\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"data_semantics_prova_6\"]\n",
    "collection = db[\"post\"]\n",
    "autori_collection = db[\"autori\"]  # Collezione che contiene gli autori\n",
    "\n",
    "DIMENSIONE_BLOCCO = 50\n",
    "\n",
    "def recupera_autori():\n",
    "    # Recupera la lista di autori dal database\n",
    "    autori_cursor = autori_collection.find()\n",
    "    autori = [autore[\"author\"] for autore in autori_cursor]  # Supponendo che il campo del nome dell'autore sia \"nome\"\n",
    "    return autori\n",
    "\n",
    "def analisi_semantica(text, autori):\n",
    "    # Supponendo che i risultati siano già ottenuti\n",
    "    risultato_ner = process_text_with_models(text, model_1_pipeline, model_2_pipeline, model_1_id, model_2_id)\n",
    "    risultato_sentiment = process_emotions_and_translate(text, model_4_pipeline, model_3_pipeline)[0]\n",
    "\n",
    "    # Filtrare i sentimenti per raggiungere uno score cumulativo di almeno 0.95\n",
    "    selected_sentiments = []\n",
    "    cumulative_score = 0\n",
    "\n",
    "    for sentiment in risultato_sentiment:\n",
    "        if cumulative_score >= 0.95:\n",
    "            break\n",
    "        selected_sentiments.append(sentiment)\n",
    "        cumulative_score += sentiment['score']\n",
    "\n",
    "    # Controlla se la lista non è vuota\n",
    "    if risultato_ner:\n",
    "        # Itera sulla lista e converte i punteggi 'score' in float64\n",
    "        for item in risultato_ner:\n",
    "            item[\"score\"] = float(item[\"score\"])  # Converte np.float32 in float64\n",
    "            # Se l'entità è un autore, etichettala come \"PER\"\n",
    "            if item[\"word\"] in autori:\n",
    "                item[\"label\"] = \"PER\"\n",
    "    #else:\n",
    "    #    print(\"La lista 'ner' è vuota!\")\n",
    "\n",
    "    risultato_sentiment = {item['label']: item['score'] for item in risultato_sentiment}\n",
    "\n",
    "    selected_sentiments = {item['label']: item['score'] for item in selected_sentiments}\n",
    "\n",
    "    # Creazione del dizionario\n",
    "    data_semantic_analysis = {\n",
    "        \"ner\": risultato_ner,\n",
    "        \"sentiment_analysis_relevant\": selected_sentiments,\n",
    "        \"sentiment_analysis_full\": risultato_sentiment\n",
    "    }\n",
    "    return data_semantic_analysis\n",
    "\n",
    "# Recupera la lista di autori una volta all'inizio\n",
    "autori = recupera_autori()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ner': [{'word': 'giulia', 'entity': 'PER', 'score': 0.5550692677497864},\n",
       "  {'word': 'boeing', 'entity': 'ORG', 'score': 0.9962664246559143},\n",
       "  {'word': 'londra', 'entity': 'LOC', 'score': 0.9963070154190063},\n",
       "  {'word': 'parigi', 'entity': 'LOC', 'score': 0.9960122108459473},\n",
       "  {'word': 'lexota', 'entity': 'MISC', 'score': 0.8247328996658325},\n",
       "  {'word': 'lexotan',\n",
       "   'entity': 'TRATTAMENTO FARMACOLOGICO (B)',\n",
       "   'score': 0.96161949634552}],\n",
       " 'sentiment_analysis_relevant': {'paura': 0.7363895177841187,\n",
       "  'nervosismo': 0.203889399766922,\n",
       "  'neutrale': 0.13923588395118713},\n",
       " 'sentiment_analysis_full': {'paura': 0.7363895177841187,\n",
       "  'nervosismo': 0.203889399766922,\n",
       "  'neutrale': 0.13923588395118713,\n",
       "  'approvazione': 0.03130808472633362,\n",
       "  'tristezza': 0.028943508863449097,\n",
       "  'realizzazione': 0.0280913058668375,\n",
       "  'cura': 0.015214819461107254,\n",
       "  'delusione': 0.012415895238518715,\n",
       "  'gioia': 0.011776150204241276,\n",
       "  'eccitazione': 0.010566255077719688,\n",
       "  'confusione': 0.010090796276926994,\n",
       "  'ottimismo': 0.009392062202095985,\n",
       "  'fastidio': 0.007430999539792538,\n",
       "  'disapprovazione': 0.007302621845155954,\n",
       "  'rilievo': 0.006080045830458403,\n",
       "  'ammirazione': 0.0060217720456421375,\n",
       "  'desiderio': 0.006003044079989195,\n",
       "  'divertimento': 0.004420675802975893,\n",
       "  'disgusto': 0.004328764043748379,\n",
       "  'sorpresa': 0.004134510178118944,\n",
       "  'amore': 0.003975382074713707,\n",
       "  'lutto': 0.003594961715862155,\n",
       "  'imbarazzo': 0.00319116935133934,\n",
       "  'curiosità': 0.0031053205020725727,\n",
       "  'rabbia': 0.0022514716256409883,\n",
       "  'rimorso': 0.001723044435493648,\n",
       "  'orgoglio': 0.0016077130567282438,\n",
       "  'gratitudine': 0.0014984116423875093}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analisi_semantica(text,autori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'giulia': {0.5550692677497864, 'PER'},\n",
       " 'boeing': {0.9962664246559143, 'ORG'},\n",
       " 'londra': {0.9963070154190063, 'LOC'},\n",
       " 'parigi': {0.9960122108459473, 'LOC'},\n",
       " 'lexota': {0.8247328996658325, 'MISC'},\n",
       " 'lexotan': {0.96161949634552, 'TRATTAMENTO FARMACOLOGICO (B)'}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risultato_ner"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
